# Advanced Query

## Histogram and calculating quantiles

We already briefly mentioned histograms when instrumenting an example service. Histograms are a metric type that allow you to track the distribution of a set of values (like request durations) by categorizing the values into range buckets and counting how many events of each bucket type an application has observed so far. Histograms are used to track durations of operations like HTTP requests, so the first bucket might count request durations from 0 to 50 ms, the next one 0 to 100 ms, and so on. Finally, Prometheus histograms always contain a bucket that ranges from 0 to infinite, effectively counting all observed values (this is equivalent to just counting all requests that have occurred).

In Prometheus, histogram metrics are exposed as multiple time series (one for each bucket) with a _bucket metric name suffix and an le label that indicates the upper bucket boundary (le stands for "less than or equal"). Additionally, you may see unrelated label dimensions on the series that were added by the instrumentation user. Each combination of other labels will contain its own "sub-histogram", or full set of possible le bucket label values.

    demo_api_request_duration_seconds_bucket{instance="lf-app-1:8080", method="POST", path="/api/bar", status="200", job="lf-app"}

This view will give you 26 output time series since the histogram has 26 buckets. The le label values will look a bit erratic, as they were auto-generated by a library helper function.

While a histogram gives you an idea of the distribution of request durations or can tell you how many of your requests take longer than, for example, 50 ms to complete (provided you have a bucket with an upper boundary of 50 ms), you often want to calculate quantiles (a more general form of percentiles) from them. For example, you might want to know in which time at least 99% of your requests complete.

In PromQL you can compute quantiles from a histogram using the histogram_quantile() function. This function takes a desired quantile value as the first parameter and a histogram (set of series labeled with le labels) as the second parameter. Note that the quantile value has to be between 0 and 1, which would correspond to the percentiles 0 and 1.

    histogram_quantile(0.9, rate(demo_api_request_duration_seconds_bucket{instance="lf-app-1:8080", method="POST", path="/api/bar", status="200", job="lf-app"}[5m]))

Note: It is important to take the rate() of a histogram before calculating quantiles from it. This ensures that only the bucket increases of the last 5 minutes (for example) are taken into account. Otherwise you would get quantiles averaged over the entire lifetime of the bucket counters, not the latency "right now".

The above still gives you a detailed drill-down of 90th percentiles for every sub-dimension (path, method, etc.). Often you want to aggregate some dimensions away and just see an overall system latency. The good news is that all sub-histograms of a given histogram metric have the same bucket configuration and each bucket is just a counter. This means that you can just sum up the corresponding bucket increase rates over a given set of dimensions to arrive at a valid aggregated histogram (which we can then feed into histogram_quantile()).


So you generate a Histogram with something like this

    sum(rate(demo_api_request_duration_seconds_bucket{instance="lf-app-1:8080", method="POST", path="/api/bar", status="200", job="lf-app"}[5m])) without(method, status)

To exclude the method and status from the label and aggregate all the remining

    histogram_quantile(0.9, sum(rate(demo_api_request_duration_seconds_bucket{instance="lf-app-1:8080", method="POST", path="/api/bar", status="200", job="lf-app"}[5m])) without(method, status))

And make the histogram quantile. To calculate the 90th percentile latency with the status and method dimensions aggregated away.

Note: Be careful not to aggregate away the *le* label. The histogram_quantile() function requires this label to be present to interpret the histogram buckets. This kind of query allows you to choose the quantile, the aggregation level, as well as the time to average over when computing quantiles from histograms.


## Filtering by sample values

You already learned earlier how to select series by their metric name and label values. Sometimes you will want to filter series by their sample value as well. The most obvious use case for this is for thresholds in alerting expressions. PromQL allows you to do this by adding a binary comparison operator between a time series vector and a scalar number.

For example, to select only the request rates for status="500" errors that are above 0.2 per second, you can query for:

    rate(demo_api_request_duration_seconds_count{instance="lf-app-1:8080", status="500", job="lf-app"}[5m]) > 0.2

You can also compare entire sets of time series with the same label-matching behavior that arithmetic binary operators have. This can be useful to correlate commonly labeled series.

For example, the following query selects all status="500" error rates that are at least 50 times larger than the total traffic for a given path, method, and instance combination: This is really good to analyze which of the server errors request takes much time.

    rate(demo_api_request_duration_seconds_count{instance="lf-app-1:8080", status="500", job="lf-app"}[5m]) * 50 > ignoring(status) sum without(status) (rate(demo_api_request_duration_seconds_count{instance="lf-app-1:8080", job="lf-app"}[5m]))


## Working with timestemp metrics

For tracking the time when some event has happened, services and exporters frequently encode a Unix timestamp in seconds into the sample value (not the sample timestamp!) of a metric. The demo service exposes a metric that tells you when the last successful run of its internal batch job happened.

    demo_batch_last_success_timestamp_seconds{job="lf-app"}

In monitoring you are often more interested in the durations since something has happened rather than the absolute timestamp.

    time() - demo_batch_last_success_timestamp_seconds{job="lf-app"}


This kind of sawtooth graph is easy to analyze with the eye: lines that go up too far represent batch jobs which are far overdue, while any drop in a line to 0 represents a successful batch job completion. Combining this expression with a value threshold allows us to detect batch jobs that have not finished within the last 1.5 minutes.

    time() - demo_batch_last_success_timestamp_seconds{job="lf-app"} > (1.5 * 60)


## Offsetting data

Sometimes you want to compare current system behavior to past behavior in one PromQL expression. For example, you might want to see what the difference (or ratio) is between the current request rate and that of a week ago on the same day. To do this, PromQL offers an offset <duration> modifier that you can add to any series selector, which time-shifts the requested data range into the past.

For example, to get the demo service request rate one hour ago (relative to each evaluation point in the graph), you can query for:

    rate(demo_api_request_duration_seconds_count{job="lf-app"}[5m] offset 1h)

You could now calculate a ratio between each current rate and the rate one hour ago.

rate(demo_api_request_duration_seconds_count{job="lf-app"}[5m]) / rate(demo_api_request_duration_seconds_count{job="lf-app"}[5m] offset 1h)

In a real service, you might use an expression like this to get an idea of whether a request rate is significantly different from the rate at the same time and day of the last week (using offset 7d).  Note that you can only use the offset modifier directly after an instant or range vector selector.


## Sorting and Limiting

In the Table view of the expression browser it's sometimes useful to sort query results by their sample value. For example, you may want to show the total memory usage of every service on a cluster, sorted descendingly, so you can easily spot the biggest memory users. You can use the sort() or sort_desc() functions to achieve this.

To see the request rates for each path in our demo service, sorted descendingly by the magnitude of the rate, query for:

    sort_desc(sum by(path) (rate(demo_api_request_duration_seconds_count{job="lf-app"}[5m])))

Sorting does not have any effect on graphs, since the X and Y values of each series are determined independently of the order in which each time series is returned in a query result. To show only a certain number of top k or bottom k results of a query (where k is an integer), you can use the topk(k, ...) or bottomk(k, ...) aggregation operators. These operators take the number of output values you want to show as their first parameter and an instant vector expression to limit as their second parameter. For example, to show the top 3 request rates for each path and method combination, query for:

    topk(3, sum by(path) (rate(demo_api_request_duration_seconds_count{job="lf-app"}[5m])))

## Inspecting scrape health

Since Prometheus is a pull-based system, it notices when it cannot scrape a target and records this fact in a metric. For every scrape, Prometheus records a synthetic up metric with the labels of the scrape target. It sets the sample value to 1 if the scrape succeeded and to 0 if the scrape failed for whatever reason. You can use this fact to query basic availability information about each job's targets.

    up{job="lf-app"}

