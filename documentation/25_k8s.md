# Prometheus and K8s

Prometheus is well suited for monitoring services in dynamic environments such as cluster schedulers. In fact, Prometheus was created specifically for this use case. Prometheus works especially well together with Kubernetes.

- Kubernetes cluster components (API Server, kubelet, etcd, DNS server) expose native Prometheus metrics endpoints
- Prometheus implements native Kubernetes-based service discovery, meaning that it can discover pods, endpoints, services, and so on, in Kubernetes clusters.

## Operational Concerns

There are a number of operational concerns to watch out for when running Prometheus on Kubernetes.

### Persistence

If you want Prometheus to keep its database between deployments, you will need to explore Kubernetes’s persistence options. For example, you may want to use a persistent volume claim (PVC) to always mount the same data volume into the Prometheus pod across restarts.

### Running Inside or Outside the cluster:

When Prometheus runs _inside_ the Kubernetes cluster, it automatically gets the right credentials mounted into its container to monitor services on Kubernetes:

1. A service account token allows Prometheus to discover cluster objects as scrape targets from the Kubernetes API Server.
2. A certificate authority (CA) file allows Prometheus to scrape metrics from secured targets like the Kubelet.
   Prometheus can also reach the service targets directly, without extra networking precautions, since its pod is part of the cluster's overlay network.

When running _outside_ of the cluster, you will need to provide Prometheus with the right credentials manually and also ensure that Prometheus can reach the metrics endpoints of services running on the Kubernetes cluster.

### RBABC

Since Kubernetes 1.7, access to the Kubernetes API Server and other components is by default heavily restricted via Kubernetes’ Role-Based Access Controls (RBAC). Prometheus needs to be run as a service account with broad read permissions to cluster resources to perform service discovery

### Prometheus Operator

As you have seen, manual operation of Prometheus and Alertmanager on Kubernetes can become complicated: you need to take care of granting sufficient permissions, mounting in persistent volumes, and performing deployments carefully.

The Prometheus Operator is an open source tool that aims to automate many of these processes using Kubernetes Custom Resource Definitions. Besides managing Prometheus servers for you, it also supports managing highly available Alertmanager clusters on top of Kubernetes. You may consider using it for operating Prometheus and Alertmanager on Kubernetes.

## Minikube

Install minikube on your local machine. Remember to close all docker containers

    docker stop $(docker ps -q)

### Configure Prometheus

Prometheus needs to be granted permissions to perform service discovery and to scrape Kubernetes's own service endpoints. To keep things simple for this lab, create a very permissive authorization policy for the Kubernetes cluster.

#### Create a clusterRole for letting Prometheus to interact with k8s

```bash
kubectl create clusterrolebinding permissive-binding \
  --clusterrole=cluster-admin \
  --user=admin \
  --user=kubelet \
  --group=system:serviceaccounts
```

This is a very permissive clusterrole, better not to do it in production.

So now we can use what we downloaded in the lf-app as an example.

The file `lf-app/prometheus-k8s-files/prometheus-config.yml` contains a configMap to load prometheus configuration into the pods

Study the configuration file contents to understand how this configuration uses Kubernetes service discovery and relabeling rules to automatically discover and scrape the Kubernetes API Server, the kubelets, and all endpoints of services on the cluster that have a `prometheus.io/scrape: "true"` annotation. Note that this and similar annotation names do not have a hard-coded meaning in Prometheus, and depending on your situation you might want to choose a different way of structuring your Prometheus-related Kubernetes annotations and how they are acted upon in relabeling rules.

Now, create a corresponding Prometheus Deployment and Service that use the ConfigMap you created above.

    kubectl apply -f prometheus-config.yml
    kubectl apply -f prometheus-deployment.yml

I use

    kubectl port-forward deploy/prometheus 30000:9090

To see prometheus interface locally

To get some web service metrics, you can run three replicas of the demo service on Kubernetes as well. However, when we built our prometheus-demo-service image with `docker build`, it created the image in containerd's `moby` namespace.

Before you can use it in Kubernetes, it needs to exist in containerd's `k8s.io` namespace. Use `docker image save` to export the image as a tar archive and use containerd’s CLI (`ctr -n k8s.io image import`) to import the image into the `k8s.io` namespace.

    docker image save prometheus-demo-service:latest -o prom-demo-svc.tar
    sudo ctr -n k8s.io image import prom-demo-svc.tar --base-name prometheus-demo-service:latest

Now apply your demo service manifest in `lf-app/prometheus-k8s-files/demo-service.yml`

    kubectl apply -f lf-app/prometheus-k8s-files/demo-service.yml

When using Minikube with the HyperKit driver, containerd runs inside the Minikube virtual machine. As a result, images built on your macOS host with `docker build` are not automatically available to Kubernetes.

To make the image available inside Minikube, you can use this command:

    docker build -t -t prometheus-demo-service:latest ./lf-app/demo-service-source
    minikube image load prometheus-demo-service:latest

Now apply your demo service manifest in `lf-app/prometheus-k8s-files/demo-service.yml`

    kubectl apply -f lf-app/prometheus-k8s-files/demo-service.yml

If you use minikube on hyperkit prometheus is not able to see the target. But on docker it should work. In targets you can see:

### Scrape Jobs configured in Prometheus

- **Job `kubelet`**  
  This monitors the health of the Kubelets themselves (you only have one in your test cluster).

- **Job `kubelet-cadvisor`**  
  This monitors the built-in cAdvisor endpoint of the Kubelets, which exposes per-container resource usage metrics for the containers running on each machine.

- **Job `kubernetes-apiserver`**  
  This monitors the health of the Kubernetes API Server instances (of which you also only have one).

### Endpoints for services with `prometheus.io/scrape: "true"` annotation

- **Job `demo-service`**  
  This is the demo service.

- **Job `kube-dns`**  
  Kubernetes's DNS server. Although you didn't set a scrape annotation on this service yourself, it comes with the correct annotation out of the box when setting up a Kubernetes cluster.

- **Job `prometheus`**  
  This is the Prometheus server monitoring itself.

- **Job `cilium-envoy`**  
  The Cilium Container Networking Interface (CNI) plugin.

The container resource usage metrics that the Kubelet's built-in cAdvisor exposes are the same as the metrics from a stand-alone cAdvisor. The only difference is that Kubernetes attaches additional Kubernetes-specific labels to the containers it starts.

The Kubernetes API Server exposes metrics about the inner events and state of the API Server itself. For example, this includes a metric called `apiserver_request_total` that counts requests to the API Server, broken out by verb (GET, LIST, etc.), API resource, resource group, and HTTP response content type and code.

To show how many service-discovery-related requests (most of which will come from the Prometheus server in our test cluster) the Kubernetes API Server is handling, query for:

    rate(apiserver_request_total{group="discovery.k8s.io", job="kubernetes-apiserver"}[5m])

This should not be a high number, but you could use a similar query to diagnose overload situations, where a client is sending too many requests to the API Server.

You can list all time series that the API Server exposes by querying in the **Console** (not Graph!) view for:

    {job="kubernetes-apiserver"}

You can query the metrics of the demo service instances that were discovered through the Kubernetes service endpoints scrape configuration in the same way that you queried them earlier on in this course, when you were running the demo service outside of Kubernetes.

The only difference is that the target labels will be slightly different. As one example, the following query should give you the total HTTP request rate:

```promql
sum by (job) (
rate(demo_api_request_duration_seconds_count[1m])
)
```

You can query the metrics of any other job whose service was annotated for scraping as well. Note that this means you don't have to update your Prometheus configuration every time you want to monitor another service's endpoints.

Simply add the `prometheus.io/scrape: "true"` annotation and the Prometheus server will discover the targets automatically.
